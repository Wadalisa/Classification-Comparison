# ğŸ§ âš”ï¸ CLASSIFICATION COMPARISON QUEST - MAIN QUEST

> *â€œBalance the data. Sharpen the model. Farm insight, not just accuracy.â€*

---

## ğŸ—ºï¸ Quest Overview

This repository contains a **classification comparison experiment** developed for COS711 Assignment 3. The quest explores how **model choice and enhancement strategies** affect classification performance, with a focus on understanding *why* improvements succeed or fail.

Two main builds are explored:

* âš”ï¸ A **baseline classifier**
* ğŸš€ An **enhanced classifier** (ResNet-based)

Rather than chasing raw scores, the quest focuses on **diagnosing weaknesses**, **learning from failed upgrades**, and identifying **clear evolution paths**.

---

## ğŸ“ Quest Inventory

```
.
â”œâ”€â”€ COS711_A3.ipynb              # Baseline classification build
â”œâ”€â”€ Assignment3_Resnet.ipynb     # Enhanced (ResNet) build
â”œâ”€â”€ README_COS711_A3.md          # Quest log
```

---

## âš™ï¸ Gear Equipped â€” Tech Stack

* **Python 3**
* **NumPy & Pandas** â€” data handling
* **Matplotlib / Seaborn** â€” visual diagnostics
* **Scikit-learn** â€” evaluation metrics
* **PyTorch / Torchvision** â€” deep learning models

---

## ğŸ“Š Data Preparation â€” World Setup

* Dataset loaded and split into **train / validation / test** sets
* Labels provided for supervised learning

Basic preprocessing was applied to enable model training and evaluation.

---

## ğŸ§  Experimental Setup â€” Strategy Phase

### ğŸ§© Builds Compared

* **Baseline Model**

  * Simple classifier used as a reference point

* **Enhanced Model**

  * Deeper architecture using **ResNet**
  * Intended to improve feature extraction and generalization

Both builds use the same dataset splits and evaluation metrics to ensure a fair comparison.

---

## ğŸŸï¸ Classification Results â€” Battle Arena

Evaluation focuses on:

* Overall accuracy
* Confusion matrices
* Qualitative inspection of class-wise behaviour

The enhanced model shows **only marginal improvement**, highlighting that architectural upgrades alone are not always sufficient.

---

## ğŸš€ Classification Enhancement â€” Power-Ups

Enhancement attempts focused on:

* Increasing model depth
* Leveraging pretrained-style architectural ideas (ResNet)

While improvements were observed, gains were **limited**, suggesting bottlenecks outside the model architecture itself.

---

## ğŸš§ Known Weaknesses & Side Quests

The main quest is complete, but several **side quests** remain to unlock the buildâ€™s full potential.

### ğŸ§© Side Quest 1: Data Insight & Class Balance

* Limited **Exploratory Data Analysis (EDA)**
* Class imbalance not explicitly addressed

**Why it matters:**

* Models may optimize for majority classes
* Overall accuracy can mask poor minority-class performance

---

### ğŸ“‰ Side Quest 2: Mediocre Performance Ceiling

* Classification results plateau early
* Marginal gains from architectural enhancement

**Why it matters:**

* Indicates data-level or loss-function-level limitations

---

### ğŸ” Side Quest 3: Result Interpretability

* Confusion matrices presented in text form
* Hard to visually diagnose class-wise errors

**Why it matters:**

* Visual diagnostics speed up failure analysis

---

## ğŸ› ï¸ Future Upgrades (Patch Notes â€” v1.1)

Planned upgrades for the next iteration:

* Add **explicit EDA** (class distributions, samples per class)
* Apply **class imbalance handling**:

  * Class-weighted loss
  * Oversampling / data augmentation
* Replace text confusion matrices with **heatmap visualizations**
* Tune hyperparameters (learning rate, batch size, epochs)

These upgrades target **root causes**, not just surface-level performance.

---

## ğŸ Quest Status

ğŸ§© **Main Quest:** Classification Comparison
ğŸ¯ **Objective:** Understand performance bottlenecks
ğŸš€ **Outcome:** Functional comparison with clear evolution paths

---

## ğŸ‘¤ Player Profile

**Wadalisa Oratile Molokwe**
Honours Student | Network Engineer & System Administrator

---

*GitHub quest log â€” built for learning, reflection, and long-term evolution.*
